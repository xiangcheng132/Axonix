import os
import pyaudio
import threading
import keyboard
import json
from vosk import Model, KaldiRecognizer
from transformers import AutoTokenizer, AutoModelForMaskedLM
import torch

# å¼ºåˆ¶ä½¿ç”¨ GPU
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# å®šä¹‰å…¨å±€å˜é‡
stop_recognition = False

# æ¨¡å‹è·¯å¾„
base_model_path = r"D:\anxio\Axonix-2\transfer\model"
vosk_model_path = os.path.join(base_model_path, "vosk-model-cn-kaldi-multicn-0.15")
bert_model_path = os.path.join(base_model_path, "bert-base-chinese")

# åˆå§‹åŒ– BERT æ¨¡å‹å’Œåˆ†è¯å™¨
try:
    bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_path)
    from transformers import BertForMaskedLM
    bert_model = BertForMaskedLM.from_pretrained(bert_model_path, ignore_mismatched_sizes=True).to(device)
    bert_model.eval()
except Exception as e:
    print(f"âŒ BERT æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    exit(1)

def correct_with_bert(text):
    """ä½¿ç”¨ BERT è¿›è¡Œè¯­ä¹‰çº é”™"""
    inputs = bert_tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)
    with torch.no_grad():
        outputs = bert_model(**inputs)
    corrected_text = bert_tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)
    return corrected_text

def recognize_audio():
    global stop_recognition

    # åŠ è½½ Vosk è¯­éŸ³è¯†åˆ«æ¨¡å‹
    if not os.path.exists(vosk_model_path):
        print("âŒ è¯­éŸ³æ¨¡å‹æœªæ‰¾åˆ°ï¼Œè¯·ä¸‹è½½æ¨¡å‹å¹¶è§£å‹åˆ°æŒ‡å®šè·¯å¾„")
        return

    model = Model(vosk_model_path)
    recognizer = KaldiRecognizer(model, 16000)
    recognizer.SetWords(True)

    # éŸ³é¢‘æµé…ç½®
    audio = pyaudio.PyAudio()
    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=4000)
    stream.start_stream()

    print("ğŸ¤ è¯­éŸ³è¯†åˆ«å¼€å§‹ï¼ˆæŒ‰ 's' é€€å‡ºï¼‰...")

    full_text = ""
    sentence_list = []  # ç”¨äºå­˜å‚¨æ¯ä¸ªçŸ­å¥

    try:
        while not stop_recognition:
            data = stream.read(4000, exception_on_overflow=False)
            if recognizer.AcceptWaveform(data):
                result_json = recognizer.Result()
                result_dict = json.loads(result_json)
                new_text = result_dict.get("text", "")
                # ç§»é™¤çŸ­å¥å†…éƒ¨çš„ç©ºæ ¼
                new_text = ''.join(new_text.split())
                full_text += " " + new_text
                sentence_list.append(new_text)  # å°†æ–°çš„çŸ­å¥æ·»åŠ åˆ°åˆ—è¡¨
                print(f"\râœ… è¯†åˆ«ç»“æœ: {' '.join(sentence_list)}", end="")
            else:
                partial_result_json = recognizer.PartialResult()
                partial_result_dict = json.loads(partial_result_json)
                partial_text = partial_result_dict.get("partial", "")
                if partial_text:
                    print(f"\rğŸ”„ ä¸´æ—¶ç»“æœ: {partial_text}", end="")
    except Exception as e:
        print(f"\nâ— è¯­éŸ³è¯†åˆ«å‡ºé”™: {e}")
    finally:
        stream.stop_stream()
        stream.close()
        audio.terminate()
        # è¾“å‡ºæœ€ç»ˆä¼˜åŒ–ç»“æœ
        if full_text:
            final_corrected_text = correct_with_bert(full_text)
            # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
            final_corrected_text = ''.join(final_corrected_text.split())
            print(f"\nğŸ æœ€ç»ˆä¼˜åŒ–ç»“æœ:\n{' '.join(sentence_list)}")
        print("ğŸ”´ è¯­éŸ³è¯†åˆ«ç»“æŸã€‚")

def listen_for_stop():
    global stop_recognition
    while not stop_recognition:
        if keyboard.is_pressed('s'):
            print("\nğŸ›‘ åœæ­¢å‘½ä»¤æ”¶åˆ°ï¼Œæ­£åœ¨é€€å‡º...")
            stop_recognition = True
            break

if __name__ == "__main__":
    # å¯åŠ¨æŒ‰é”®ç›‘å¬çº¿ç¨‹
    stop_thread = threading.Thread(target=listen_for_stop, daemon=True)
    stop_thread.start()

    # å¯åŠ¨è¯­éŸ³è¯†åˆ«
    recognize_audio()